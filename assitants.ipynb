{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three agents doing RAG\n",
    "\n",
    "This Python notebook demonstrates use of three OpenAI assitants to improve quality of RAG results by pre-processing the user prompt into a search expression.\n",
    "\n",
    "Based on this [sample](https://github.com/Azure-Samples/azureai-samples/tree/main/scenarios/Assistants/multi-agent)\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "+ An Azure subscription, with [access to Azure OpenAI](https://aka.ms/oai/access).\n",
    " \n",
    "+ Azure AI Search, any tier, but we recommend Basic or higher for this workload. [Enable semantic ranker](https://learn.microsoft.com/azure/search/semantic-how-to-enable-disable) if you want to run a hybrid query with semantic ranking.\n",
    "\n",
    "+ A deployment of the `text-embedding-3-large` model on Azure OpenAI.\n",
    "\n",
    "+ A deployment of the `gpt-4o` model on Azure OpenAI. \n",
    "\n",
    "+ Azure Blob Storage. This notebook connects to your storage account and loads a container with the sample CSV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a Python virtual environment in Visual Studio Code\n",
    "\n",
    "1. Open the Command Palette (Ctrl+Shift+P).\n",
    "1. Search for **Python: Create Environment**.\n",
    "1. Select **Venv**.\n",
    "1. Select a Python interpreter. Choose 3.10 or later.\n",
    "\n",
    "It can take a minute to set up. If you run into problems, see [Python environments in VS Code](https://code.visualstudio.com/docs/python/environments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    ")\n",
    "\n",
    "azure_openai_model_dimensions = int(os.getenv(\"AZURE_OPENAI_EMBEDDING_DIMENSIONS\", 1024))\n",
    "\n",
    "sortDescription = \"\"\"\n",
    "Specify a custom sort order for search results. Format is a comma-separated list of up to 32 order-by clauses. An order-by clause consists of a field name to order by and optional direction.\n",
    "You must generate one clause for every field you want to sort by.\n",
    "If a direction is not specified, the default is ascending. \n",
    "Examples:\n",
    "Query: Find the youngest employee\n",
    "Response: Age asc\n",
    "\n",
    "Query: Who is the youngest, tallest employee\n",
    "Response: Height desc, Age asc\n",
    "\"\"\"\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_query_options\",\n",
    "            \"description\": \"Given a question, get any additional Azure Search query parameters required to answer the question. If no additional query parameters are required to answer the question, don't return any.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"orderBy\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": sortDescription,\n",
    "                    },\n",
    "                    \"filter\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Specify inclusion or exclusion criteria for search results. Format is an Azure Search OData boolean expression. Example: Age le 4 or not (Age gt 8)\"\n",
    "                    },\n",
    "                    \"search\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Specify a query string used to search text and vectors in an Azure Search index in order to answer the provided question. If no query string is required to answer the question, return * or no query string at all\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]\n",
    "fields = [  \n",
    "    SearchField(name=\"AzureSearch_DocumentKey\",  key=True, type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"ID\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False),  \n",
    "    SearchField(name=\"Name\", type=SearchFieldDataType.String, filterable=True),  \n",
    "    SearchField(name=\"Age\", type=SearchFieldDataType.Int32, sortable=True, filterable=True, facetable=False),  \n",
    "    SearchField(name=\"Title\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),\n",
    "    SearchField(name=\"Description\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),\n",
    "    SearchField(name=\"TitleVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=azure_openai_model_dimensions, vector_search_profile_name=\"myHnswProfile\"),\n",
    "    SearchField(name=\"DescriptionVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=azure_openai_model_dimensions, vector_search_profile_name=\"myHnswProfile\"),\n",
    "]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create user_proxy assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_pa = \"user_proxy\"\n",
    "agent_arr = [\"dalle_assistant\", \"vision_assistant\"]\n",
    "agent_string = \"\"\n",
    "for item in agent_arr:\n",
    "    agent_string += f\"{item}\\n\"\n",
    "\n",
    "instructions_pa = f\"\"\"As a user proxy agent, your primary function is to streamline dialogue between the user and the specialized agents within this group chat. You are tasked with articulating user inquiries with clarity to the relevant agents and maintaining a steady flow of communication to guarantee the user's request is comprehensively addressed. Please withhold your response to the user until the task is completed, unless an issue is flagged by the respective agent or when you can provide a conclusive reply.\n",
    "\n",
    "You have access to the local file system where files are stores. For example, you can access the image generated by the Dall-e assistant and send it to the Vision assistant for analysis.\n",
    "\n",
    "You have access to the following agents to accomplish the task:\n",
    "{agent_string}\n",
    "If the agents above are not enough or are out of scope to complete the task, then run send_message with the name of the agent.\n",
    "\n",
    "When outputting the agent names, use them as the basis of the agent_name in the send message function, even if the agent doesn't exist yet.\n",
    "\n",
    "Run the send_message function for each agent name generated. \n",
    "\n",
    "Do not ask for followup questions, run the send_message function according to your initial input.\n",
    "\n",
    "Plan:\n",
    "1. prompt2search creates AI Search API payload and calls Azure Search API\n",
    "2. answer_assistant receives the response from Azure Search API and formats the response for the user\n",
    "\n",
    "Now take a deep breath and accomplish the plan above. Always follow the plan step by step in the exact order and do not ask for followup questions. Do not skip any steps in the plan, do not repeat any steps and always complete the entire plan in order step by step.  \n",
    "\"\"\"\n",
    "\n",
    "tools = [\n",
    "    {\"type\": \"code_interpreter\"},\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"send_message\",\n",
    "            \"description\": \"Send messages to other agents in this group chat.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The message to be sent\",\n",
    "                    },\n",
    "                    \"agent_name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The name of the agent to execute the task.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"query\", \"agent_name\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "verbose_output = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from openai.types.beta import Thread\n",
    "from openai.types.beta import Assistant\n",
    "    \n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version=\"2024-05-01-preview\",\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "# Create assistants\n",
    "user_proxy = client.beta.assistants.create(\n",
    "    name=\"User Proxy\",\n",
    "    instructions=f\"You are a user proxy AI assistant who helps users interact with the system. You can answer questions, provide recommendations, and help users navigate the system.\",\n",
    "    tools=tools,\n",
    "    model=os.getenv(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\")\n",
    ")\n",
    "prompt2search_assitant = client.beta.assistants.create(\n",
    "    name=\"Prompt to Search assistant\",\n",
    "    instructions=f\"You are a helpful AI assistant who makes interesting visualizations based on data.\" \n",
    "    f\"You have access to a sandboxed environment for writing and testing code.\"\n",
    "    f\"When you are asked to create a visualization you should follow these steps:\"\n",
    "    f\"1. Write the code.\"\n",
    "    f\"2. Anytime you write new code display a preview of the code to show your work.\"\n",
    "    f\"3. Run the code to confirm that it runs.\"\n",
    "    f\"4. If the code is successful display the visualization.\"\n",
    "    f\"5. If the code is unsuccessful display the error message and try to revise the code and rerun going through the steps from above again.\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    model=\"gpt-4o\" #You must replace this value with the deployment name for your model.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Blob Storage and load documents\n",
    "\n",
    "Retrieve documents from Blob Storage. You can use the sample documents in the data/documents folder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup sample data in zoo\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient  \n",
    "import glob\n",
    "\n",
    "def upload_sample_documents(\n",
    "        blob_connection_string: str,\n",
    "        blob_container_name: str,\n",
    "        use_user_identity: bool = True\n",
    "    ):\n",
    "    # Connect to Blob Storage\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(conn_str=blob_connection_string, credential=DefaultAzureCredential() if use_user_identity else None)\n",
    "    container_client = blob_service_client.get_container_client(blob_container_name)\n",
    "    if not container_client.exists():\n",
    "        container_client.create_container()\n",
    "\n",
    "    documents_directory = \"csv_data\"\n",
    "    csv_files = glob.glob(os.path.join(documents_directory, '*.csv'))\n",
    "    for file in csv_files:\n",
    "        with open(file, \"rb\") as data:\n",
    "            name = os.path.basename(file)\n",
    "            if not container_client.get_blob_client(name).exists():\n",
    "                container_client.upload_blob(name=name, data=data)\n",
    "\n",
    "upload_sample_documents(\n",
    "    blob_connection_string=blob_connection_string,\n",
    "    blob_container_name=blob_container_name,\n",
    "    # Set to false if you want to use credentials included in the blob connection string\n",
    "    # Otherwise your identity will be used as credentials\n",
    "    use_user_identity=False\n",
    ")\n",
    "print(f\"Setup sample data in {blob_container_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a blob data source connector on Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source 'employees-blob' created or updated\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SoftDeleteColumnDeletionDetectionPolicy\n",
    ")\n",
    "\n",
    "# Create a data source\n",
    "# NOTE: To remove records from a search index, add a column to the row \"IsDeleted\" set to \"True\". The next indexer run will remove this record\n",
    "# To learn more please visit https://learn.microsoft.com/en-us/azure/search/search-howto-index-one-to-many-blobs\n",
    "indexer_client = SearchIndexerClient(endpoint, credential)\n",
    "container = SearchIndexerDataContainer(name=blob_container_name)\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=f\"{index_name}-blob\",\n",
    "    type=\"azureblob\",\n",
    "    connection_string=search_blob_connection_string,\n",
    "    container=container,\n",
    "    data_deletion_detection_policy=SoftDeleteColumnDeletionDetectionPolicy(soft_delete_column_name=\"IsDeleted\", soft_delete_marker_value=\"True\")\n",
    ")\n",
    "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a search index\n",
    "\n",
    "Vector and nonvector content is stored in a search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_name is not a known attribute of class <class 'azure.search.documents.indexes._generated.models._models_py3.AzureOpenAIParameters'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employees created\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIParameters,\n",
    "    SemanticConfiguration,\n",
    "    SemanticSearch,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SearchIndex\n",
    ")\n",
    "\n",
    "# Create a search index\n",
    "# NOTE: You must adjust these fields based on your CSV Schema.\n",
    "# There is no chunking of the description or title fields in this sample.\n",
    "# There is a separate AzureSearch_DocumentKey for the key automatically generated by the indexer\n",
    "# Learn more at https://learn.microsoft.com/en-us/azure/search/search-howto-index-csv-blobs\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)  \n",
    "fields = [  \n",
    "    SearchField(name=\"AzureSearch_DocumentKey\",  key=True, type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"ID\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False),  \n",
    "    SearchField(name=\"Name\", type=SearchFieldDataType.String, filterable=True),  \n",
    "    SearchField(name=\"Age\", type=SearchFieldDataType.Int32, sortable=True, filterable=True, facetable=False),  \n",
    "    SearchField(name=\"Title\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),\n",
    "    SearchField(name=\"Description\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),\n",
    "    SearchField(name=\"TitleVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=azure_openai_model_dimensions, vector_search_profile_name=\"myHnswProfile\"),\n",
    "    SearchField(name=\"DescriptionVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=azure_openai_model_dimensions, vector_search_profile_name=\"myHnswProfile\"),\n",
    "]  \n",
    "  \n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(name=\"myHnsw\"),\n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer=\"myOpenAI\",  \n",
    "        )\n",
    "    ],  \n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            azure_open_ai_parameters=AzureOpenAIParameters(  \n",
    "                resource_uri=azure_openai_endpoint,  \n",
    "                deployment_id=azure_openai_embedding_deployment,\n",
    "                model_name=azure_openai_model_name,\n",
    "                api_key=azure_openai_key,\n",
    "            ),\n",
    "        ),  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "semantic_config = SemanticConfiguration(  \n",
    "    name=\"my-semantic-config\",  \n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"Title\"),\n",
    "        content_fields=[SemanticField(field_name=\"Description\")]  \n",
    "    ),  \n",
    ")\n",
    "\n",
    "# Create the semantic search with the configuration  \n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])  \n",
    "  \n",
    "# Create the search index\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)  \n",
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} created\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a skillset\n",
    "\n",
    "Skills drive integrated vectorization. [AzureOpenAIEmbedding](https://learn.microsoft.com/azure/search/cognitive-search-skill-azure-openai-embedding) handles calls to Azure OpenAI, using the connection information you provide in the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    SearchIndexerSkillset\n",
    ")\n",
    "\n",
    "# Create a skillset  \n",
    "skillset_name = f\"{index_name}-skillset\"\n",
    "  \n",
    "title_embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "    description=\"Skill to generate title embeddings via Azure OpenAI\",  \n",
    "    context=\"/document\",  \n",
    "    resource_uri=azure_openai_endpoint,  \n",
    "    deployment_id=azure_openai_embedding_deployment,  \n",
    "    model_name=azure_openai_model_name,\n",
    "    dimensions=azure_openai_model_dimensions,\n",
    "    api_key=azure_openai_key,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/Title\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"TitleVector\")  \n",
    "    ],  \n",
    ")\n",
    "\n",
    "description_embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "    description=\"Skill to generate description embeddings via Azure OpenAI\",  \n",
    "    context=\"/document\",  \n",
    "    resource_uri=azure_openai_endpoint,  \n",
    "    deployment_id=azure_openai_embedding_deployment,  \n",
    "    model_name=azure_openai_model_name,\n",
    "    dimensions=azure_openai_model_dimensions,\n",
    "    api_key=azure_openai_key,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/Description\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"DescriptionVector\")  \n",
    "    ],  \n",
    ")  \n",
    "\n",
    "skills = [title_embedding_skill, description_embedding_skill]\n",
    "\n",
    "skillset = SearchIndexerSkillset(  \n",
    "    name=skillset_name,  \n",
    "    description=\"Skillset to chunk documents and generating embeddings\",  \n",
    "    skills=skills\n",
    ")\n",
    "  \n",
    "client = SearchIndexerClient(endpoint, credential)  \n",
    "client.create_or_update_skillset(skillset)  \n",
    "print(f\"{skillset.name} created\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexer,\n",
    "    FieldMapping,\n",
    "    FieldMappingFunction,\n",
    "    IndexingParameters,\n",
    "    IndexingParametersConfiguration,\n",
    "    BlobIndexerParsingMode\n",
    ")\n",
    "\n",
    "# Create an indexer  \n",
    "indexer_name = f\"{index_name}-indexer\"  \n",
    "indexer_parameters = IndexingParameters(\n",
    "        configuration=IndexingParametersConfiguration(\n",
    "            parsing_mode=BlobIndexerParsingMode.DELIMITED_TEXT,\n",
    "            query_timeout=None,\n",
    "            first_line_contains_headers=True))\n",
    "\n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to index documents and generate embeddings\",  \n",
    "    skillset_name=skillset_name,  \n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name,\n",
    "    parameters=indexer_parameters,\n",
    "    field_mappings=[FieldMapping(source_field_name=\"AzureSearch_DocumentKey\", target_field_name=\"AzureSearch_DocumentKey\", mapping_function=FieldMappingFunction(name=\"base64Encode\"))],\n",
    "    output_field_mappings=[\n",
    "        FieldMapping(source_field_name=\"/document/TitleVector\", target_field_name=\"TitleVector\"),\n",
    "        FieldMapping(source_field_name=\"/document/DescriptionVector\", target_field_name=\"DescriptionVector\")\n",
    "    ]\n",
    ")  \n",
    "\n",
    "indexer_client = SearchIndexerClient(endpoint, credential)  \n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
    "  \n",
    "# Run the indexer  \n",
    "indexer_client.run_indexer(indexer_name)  \n",
    "print(f'{indexer_name} is created and running. If queries return no results, please wait a bit and try again.')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a hybrid search\n",
    "\n",
    "This example shows a hybrid vector search using the vectorizable text query, all you need to do is pass in text and your vectorizer will handle the query vectorization.\n",
    "Ask a zoo employment related question that can be answered just using the title and description fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "\n",
    "# Pure Vector Search\n",
    "query = \"Cleans fish tanks\"\n",
    "  \n",
    "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=50, fields=\"TitleVector,DescriptionVector\")\n",
    "# Use the below query to pass in the raw vector query instead of the query vectorization\n",
    "# vector_query = RawVectorQuery(vector=generate_embeddings(query), k_nearest_neighbors=3, fields=\"vector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"ID\", \"Name\", \"Title\", \"Description\"],\n",
    "    top=3\n",
    ")  \n",
    "  \n",
    "for result in results:\n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"ID: {result['ID']}\")  \n",
    "    print(f\"Name: {result['Name']}\")  \n",
    "    print(f\"Title: {result['Title']}\")\n",
    "    print(f\"Description: {result['Description']}\")   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer questions that require data analysis\n",
    "\n",
    "Some questions require a deeper understanding of the data schema. For example, the question \"Which employees are older than 40?\" requires using [filtering](https://learn.microsoft.com/en-us/azure/search/search-filters) and \"Who is the youngest employee\" requires using [sorting](https://learn.microsoft.com/en-us/azure/search/search-pagination-page-layout). Use your [chat deployment](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/completions) to create the correct Azure Search query to answer the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "openai_credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(openai_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_key,\n",
    "    azure_ad_token_provider=token_provider if not azure_openai_key else None\n",
    ")\n",
    "\n",
    "# See https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/function-calling for more information\n",
    "# NOTE: Updating the tool definition with specific examples related to your data will help improve the accuracy.\n",
    "# \"Specify a custom sort order for search results. Format is a comma-separated list of up to 32 order-by clauses. If a direction is not specified, the default is ascending. Example: ID, Age desc, Title asc\",\n",
    "sortDescription = \"\"\"\n",
    "Specify a custom sort order for search results. Format is a comma-separated list of up to 32 order-by clauses. An order-by clause consists of a field name to order by and optional direction.\n",
    "You must generate one clause for every field you want to sort by.\n",
    "If a direction is not specified, the default is ascending. \n",
    "Examples:\n",
    "Query: Find the youngest employee\n",
    "Response: Age asc\n",
    "\n",
    "Query: Who is the youngest, tallest employee\n",
    "Response: Height desc, Age asc\n",
    "\"\"\"\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_query_options\",\n",
    "            \"description\": \"Given a question, get any additional Azure Search query parameters required to answer the question. If no additional query parameters are required to answer the question, don't return any.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"orderBy\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": sortDescription,\n",
    "                    },\n",
    "                    \"filter\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Specify inclusion or exclusion criteria for search results. Format is an Azure Search OData boolean expression. Example: Age le 4 or not (Age gt 8)\"\n",
    "                    },\n",
    "                    \"search\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Specify a query string used to search text and vectors in an Azure Search index in order to answer the provided question. If no query string is required to answer the question, return * or no query string at all\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Specifically instruct the model to only use filterable fields when creating query options\n",
    "filterable_fields = \", \".join([field.name for field in fields if field.filterable])\n",
    "query_options_system_prompt = f\"Create options for Azure Search queries. If you are creating filters, you may only use the following fields: {filterable_fields}.\"\n",
    "def get_query_options(query: str) -> dict:\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_chat_deployment,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": query_options_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "        tools=tools,\n",
    "        tool_choice={ \"type\": \"function\", \"function\": { \"name\": \"get_query_options\" } },\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "\n",
    "    # Only include query options if the model provides them\n",
    "    if len(response_message.tool_calls) == 1:\n",
    "        try:\n",
    "            return json.loads(response_message.tool_calls[0].function.arguments)\n",
    "        except:\n",
    "            return {}\n",
    "\n",
    "    return {}\n",
    "\n",
    "\n",
    "answer_query_results_system_prompt = f\"The following question requires search results to provide an answer. Use the provided search results to answer the question. If you can't answer the question using the search results, say I don't know.\"\n",
    "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "def answer_query(query: str) -> str:\n",
    "    # Parse the query options returned by the model\n",
    "    query_options = get_query_options(query)\n",
    "    print(\"Query Options:\", query_options)\n",
    "    query_option_search = query_options.get(\"search\")\n",
    "    vector_queries = None\n",
    "    if query_option_search and query_option_search != \"*\":\n",
    "        vector_queries = [VectorizableTextQuery(text=query_option_search, k_nearest_neighbors=50, fields=\"TitleVector,DescriptionVector\")]\n",
    "\n",
    "    query_option_order_by = query_options.get(\"orderBy\")\n",
    "    order_by = None\n",
    "    if query_option_order_by:\n",
    "        order_by = query_option_order_by.split(\",\")\n",
    "        # foreach order_by, check whether it starts with a valid field name\n",
    "        # if not, throw an exception that the field is not sortable\n",
    "        for order in order_by:\n",
    "            field = order.strip().split(\" \")[0]\n",
    "            if field not in [field.name for field in fields if field.sortable]:\n",
    "                # Consider saving this info in audit trail to identify fields which should be made sortable\n",
    "                raise Exception(f\"Field '{field}' is not sortable field in the index and is needed by the prompt\")\n",
    "\n",
    "    # This sample only uses specific fields to answer questions. Update these fields for your own data\n",
    "    columns = [\"ID\", \"Age\", \"Name\", \"Title\", \"Description\"]\n",
    "    search_results = search_client.search(\n",
    "        search_text=query_option_search,\n",
    "        vector_queries=vector_queries,\n",
    "        top=5,\n",
    "        order_by=order_by,\n",
    "        filter=query_options.get(\"filter\"),\n",
    "        select=columns\n",
    "    )\n",
    "\n",
    "    # Convert the search results to markdown for use by the model\n",
    "    results = [ { column: result[column] for column in columns } for result in search_results ]\n",
    "    results_markdown_table = pd.DataFrame(results).to_markdown(index=False)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_chat_deployment,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": answer_query_results_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": results_markdown_table },\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    )\n",
    "    # Return the generated answer, query options, and results table for analysis\n",
    "    return response.choices[0].message.content, query_options, results_markdown_table\n",
    "\n",
    "def print_answer(answer, query_options, results):\n",
    "    print(\"Generated Answer:\", answer)\n",
    "    print(\"Generated Query Options:\", query_options)\n",
    "    print(\"Search Results\")\n",
    "    print(results)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer sample questions\n",
    "\n",
    "These questions may require filtering and sorting in addition to regular search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Options: {'orderBy': 'Age asc'}\n",
      "Generated Answer: The youngest employee is Jane Smith, who is 20 years old.\n",
      "Generated Query Options: {'orderBy': 'Age asc'}\n",
      "Search Results\n",
      "|   ID |   Age | Name            | Title              | Description                      |\n",
      "|-----:|------:|:----------------|:-------------------|:---------------------------------|\n",
      "|    2 |    20 | Jane Smith      | Veterinarian       | Provides medical care to animals |\n",
      "|   15 |    21 | Isabella Martin | Researcher         | Conducts research on wildlife    |\n",
      "|    3 |    23 | Alice Johnson   | Animal Trainer     | Trains animals for performances  |\n",
      "|    4 |    23 | Robert Brown    | Tour Guide         | Guides visitors through the zoo  |\n",
      "|   11 |    26 | Olivia Thomas   | Facilities Manager | Manages zoo facilities           |\n"
     ]
    }
   ],
   "source": [
    "answer, query_options, results = answer_query(\"Who is the youngest employee?\")\n",
    "print_answer(answer, query_options, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Options: {'orderBy': 'Age asc, Height desc'}\n",
      "Field 'Height' is not sortable field in the index and is needed by the prompt\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    answer, query_options, results = answer_query(\"Who is the tallest, youngest employee?\")\n",
    "    print_answer(answer, query_options, results)    \n",
    "except Exception as e:\n",
    "    if hasattr(e, 'message'):\n",
    "        print(e.message)\n",
    "    else:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer, query_options, results = answer_query(\"Who provides community updates about the zoo?\")\n",
    "print_answer(answer, query_options, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer, query_options, results = answer_query(\"Of the employees who are older than 40, who is the youngest?\")\n",
    "print_answer(answer, query_options, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer, query_options, results = answer_query(\"Who are the employees who's first name is Alice?\")\n",
    "print_answer(answer, query_options, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer, query_options, results = answer_query(\"Is there an employee named Scarlett?\")\n",
    "print_answer(answer, query_options, results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
